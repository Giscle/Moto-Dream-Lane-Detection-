{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final notebook for detecting lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the custom functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    # Retrieve the number of color channels of the image.\n",
    "    #channel_count = img.shape[2]\n",
    "    \n",
    "    # color used to fill polygon\n",
    "    match_mask_color = 255\n",
    "      \n",
    "    # Fill the polygon with white\n",
    "    cv2.fillPoly(mask, vertices, (255,255,255))\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gamma_correction(RGBimage, correct_param = 0.35,equalizeHist = False):\n",
    "    red = RGBimage[:,:,2]\n",
    "    green = RGBimage[:,:,1]\n",
    "    blue = RGBimage[:,:,0]\n",
    "    \n",
    "    red = red/255.0\n",
    "    red = cv2.pow(red, correct_param)\n",
    "    red = np.uint8(red*255)\n",
    "    if equalizeHist:\n",
    "        red = cv2.equalizeHist(red)\n",
    "    \n",
    "    green = green/255.0\n",
    "    green = cv2.pow(green, correct_param)\n",
    "    green = np.uint8(green*255)\n",
    "    if equalizeHist:\n",
    "        green = cv2.equalizeHist(green)\n",
    "        \n",
    "    \n",
    "    blue = blue/255.0\n",
    "    blue = cv2.pow(blue, correct_param)\n",
    "    blue = np.uint8(blue*255)\n",
    "    if equalizeHist:\n",
    "        blue = cv2.equalizeHist(blue)\n",
    "    \n",
    "\n",
    "    output = cv2.merge((blue,green,red))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hsv_filter(image, min_val_y, max_val_y,  min_val_w, max_val_w):\n",
    "    \"\"\"\n",
    "    A function returning a mask for pixels within min_val - max_val range\n",
    "    Inputs:\n",
    "    - image - a BGR image you want to apply function on\n",
    "    - min_val_y - array of shape (3,) giving minumum HSV values for yellow color\n",
    "    - max_val_y - array of shape (3,) giving maximum HSV values for yellow color\n",
    "    - min_val_w - array of shape (3,) giving minumum HSV values for white color\n",
    "    - max_val_w - array of shape (3,) giving maximum HSV values for white color\n",
    "    Returns:\n",
    "    - img_filtered - image of pixels being in given threshold\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask_yellow = cv2.inRange(hsv, min_val_y, max_val_y)\n",
    "    mask_white = cv2.inRange(hsv, min_val_w, max_val_w)\n",
    "    mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "    img_filtered = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_transform(original, gray_img, threshold, discard_horizontal = 0.4):\n",
    "    \"\"\"\n",
    "    A function fitting lines that intersect >=threshold white pixels\n",
    "    Input:\n",
    "    - original - image we want to draw lines on\n",
    "    - gray_img - image with white/black pixels, e.g. a result of Canny Edge Detection\n",
    "    - threshold - if a line intersects more than threshold white pixels, draw it\n",
    "    - discard_horizontal - smallest abs derivative of line that we want to take into account\n",
    "    Return:\n",
    "    - image_lines - result of applying the function\n",
    "    - lines_ok - rho and theta\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLines(gray_img, 0.5, np.pi / 360, threshold)\n",
    "    image_lines = original\n",
    "    lines_ok = [] #list of parameters of lines that we want to take into account (not horizontal)\n",
    "            \n",
    "    if lines is not None:\n",
    "        for i in range(0, len(lines)):\n",
    "            rho = lines[i][0][0]\n",
    "            theta = lines[i][0][1]\n",
    "            #discard horizontal lines\n",
    "            m = -math.cos(theta)/(math.sin(theta)+1e-10) #adding some small value to avoid dividing by 0\n",
    "            if abs(m) < discard_horizontal:\n",
    "                continue\n",
    "            else:\n",
    "                a = math.cos(theta)\n",
    "                b = math.sin(theta)\n",
    "                x0 = a * rho\n",
    "                y0 = b * rho\n",
    "                pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "                pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "                cv2.line(image_lines, pt1, pt2, (0,0,255), 2, cv2.LINE_AA)\n",
    "                lines_ok.append([rho,theta])\n",
    "        \n",
    "    lines_ok = np.array(lines_ok)\n",
    "                    \n",
    "    return image_lines, lines_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(lines, original, region_of_interest_points, eps = 0.05, min_samples = 3):\n",
    "    \"\"\"\n",
    "    A function using DBSCAN clustering algorithm for finding best lines to be drawn on the output video\n",
    "    Inputs:\n",
    "    - lines - output of hough tranform function, array containing parameters of found lines\n",
    "    - original - image we want to draw final lines on\n",
    "    - region_of_interest_points - for drawing lines of desired length\n",
    "    Output:\n",
    "    - img - image with detected lane lines drawn\n",
    "    \"\"\"\n",
    "    img = original\n",
    "    img_lines = np.zeros_like(img, dtype=np.int32)\n",
    "\n",
    "    if lines.shape[0] != 0:\n",
    "        #preprocessing features to be in (0-1) range\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(lines)\n",
    "        lines = scaler.fit_transform(lines)\n",
    "\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples).fit(lines) #applying DBSCAN Algorithm on our normalized lines\n",
    "        labels = db.labels_\n",
    "\n",
    "        lines = scaler.inverse_transform(lines) #getting back our original values\n",
    "\n",
    "        grouped = defaultdict(list)\n",
    "        #grouping lines by clusters\n",
    "        for i, label in enumerate(labels):\n",
    "            grouped[label].append([lines[i,0],lines[i,1]])\n",
    "\n",
    "        num_clusters = np.max(labels) + 1\n",
    "        means = []\n",
    "        #getting mean values by cluster\n",
    "        for i in range(num_clusters):\n",
    "            mean = np.mean(np.array(grouped[i]), axis=0)\n",
    "            means.append(mean)\n",
    "\n",
    "        means = np.array(means)\n",
    "        \n",
    "        #printing the result on original image\n",
    "        for rho, theta in means:\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "            pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "            cv2.line(img, pt1, pt2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting video and applying lane line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capturing video\n",
    "cap = cv2.VideoCapture('Driving_India_Night.mp4')\n",
    "\n",
    "#defining corners for ROI\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "topLeftPt = (width*(3.0/8), height*(2.7/5))\n",
    "topRightPt = (width*(5.0/8), height*(2.7/5))\n",
    "\n",
    "region_of_interest_points = [\n",
    "(0, height),\n",
    "(0, height*(3.4/5)),\n",
    "topLeftPt,\n",
    "topRightPt,\n",
    "(width, height*(3.4/5)),\n",
    "(width, height),\n",
    "]\n",
    "\n",
    "#defining color thresholds\n",
    "min_val_y = np.array([15,80,190])\n",
    "max_val_y = np.array([30,255,255])\n",
    "min_val_w = np.array([0,0,195])\n",
    "max_val_w = np.array([255, 80, 255])\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame2 = frame\n",
    "    if ret:\n",
    "        gamma = gamma_correction(frame, correct_param = 0.2,equalizeHist = False)\n",
    "        cv2.imshow('gamma', gamma)\n",
    "        cropped = region_of_interest(gamma, np.array([region_of_interest_points], np.int32))\n",
    "        cv2.imshow('cropped', cropped)\n",
    "        bilateral = cv2.bilateralFilter(cropped, 9, 80, 80)\n",
    "        cv2.imshow('bilateral', bilateral)\n",
    "        hsv = hsv_filter(bilateral, min_val_y, max_val_y,  min_val_w, max_val_w)\n",
    "        cv2.imshow('hsv', hsv)\n",
    "        canny = cv2.Canny(hsv, 100, 255)\n",
    "        cv2.imshow('canny', canny)\n",
    "        hough, lines = hough_transform(frame, canny, 14, discard_horizontal = 0.4)\n",
    "        cv2.imshow('hough', hough)\n",
    "        final = clustering(lines, frame2, np.array([region_of_interest_points], np.int32), eps = 0.5, min_samples = 4)\n",
    "        cv2.imshow('final', final)\n",
    "        \n",
    "\n",
    "        \n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
